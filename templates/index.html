<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">
    <title>Audio Recorder</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .main-container {
            display: flex;
            gap: 30px;
            max-width: 1200px;
            width: 100%;
            justify-content: center;
            align-items: flex-start;
        }

        .panel {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            padding: 40px;
            width: 500px;
            text-align: center;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            padding: 40px;
            max-width: 600px;
            width: 100%;
            text-align: center;
        }

        h1 {
            color: #333;
            margin-bottom: 30px;
            font-size: 2.5em;
            font-weight: 300;
        }

        .recorder-section {
            margin-bottom: 40px;
        }

        .record-button {
            background: linear-gradient(45deg, #ff6b6b, #ee5a24);
            color: white;
            border: none;
            border-radius: 50px;
            padding: 20px 40px;
            font-size: 1.2em;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
            min-width: 120px;
        }

        .record-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 20px rgba(0, 0, 0, 0.2);
        }

        .record-button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }

        .record-button.recording {
            background: linear-gradient(45deg, #ff4757, #ff3838);
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }

        .status {
            margin: 20px 0;
            padding: 15px;
            border-radius: 10px;
            font-weight: 500;
        }

        .status.recording {
            background: #ffeaa7;
            color: #d63031;
        }

        .status.success {
            background: #55a3ff;
            color: white;
        }

        .status.error {
            background: #ff7675;
            color: white;
        }

        .audio-player {
            margin: 20px 0;
            width: 100%;
        }



        .hidden {
            display: none;
        }

        .timer {
            font-size: 1.5em;
            font-weight: bold;
            color: #333;
            margin: 20px 0;
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            flex-wrap: wrap;
        }

        .settings-section {
            margin-top: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 15px;
            border: 1px solid #e9ecef;
        }

        .settings-section h3 {
            color: #333;
            margin-bottom: 15px;
            font-size: 1.2em;
            font-weight: 500;
        }

        .settings-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }

        .setting-item {
            display: flex;
            flex-direction: column;
            align-items: flex-start;
        }

        .setting-item label {
            font-weight: 500;
            color: #555;
            margin-bottom: 5px;
            font-size: 0.9em;
        }

        .setting-input {
            width: 100%;
            padding: 8px 12px;
            border: 1px solid #ddd;
            border-radius: 8px;
            font-size: 1em;
            background: white;
            transition: border-color 0.3s ease;
        }

        .setting-input:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 2px rgba(102, 126, 234, 0.1);
        }

        .stream-panel {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            padding: 40px;
            width: 500px;
            text-align: center;
        }

        .video-container {
            width: 100%;
            height: 600px;
            background: #f8f9fa;
            border: 2px dashed #dee2e6;
            border-radius: 15px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 20px 0;
            position: relative;
            overflow: hidden;
        }

        .video-container.streaming {
            border-color: #28a745;
            background: #000;
        }

        .video-placeholder {
            color: #6c757d;
            font-size: 1.1em;
            font-weight: 500;
        }

                 .stream-video {
             width: 100%;
             height: 100%;
             display: block;
             background: #000;
         }

        .stream-video.active {
            display: block;
        }

        .stream-status {
            margin: 15px 0;
            padding: 10px;
            border-radius: 8px;
            font-weight: 500;
            font-size: 0.9em;
        }

        .stream-status.waiting {
            background: #fff3cd;
            color: #856404;
        }

        .stream-status.streaming {
            background: #d4edda;
            color: #155724;
        }

        .stream-status.error {
            background: #f8d7da;
            color: #721c24;
        }
    </style>
</head>
<body>
    <div class="main-container">
        <!-- Left Panel - Audio Recording -->
        <div class="panel">
            <h1>Audio Recording</h1>
            
            <div class="recorder-section">
                <div class="timer" id="timer">00:00</div>
                
                                 <div class="controls">
                     <button class="record-button" id="recordButton">
                         üéôÔ∏è Start Recording
                     </button>
                 </div>
                
                <div class="status hidden" id="status"></div>
                
                <audio class="audio-player hidden" id="audioPlayer" controls></audio>
            </div>
            
            <div class="settings-section">
                <h3>Processing Settings</h3>
                <div class="settings-grid">
                    <div class="setting-item">
                        <label for="fpsInput">FPS:</label>
                        <input type="number" id="fpsInput" value="15" min="1" max="60" class="setting-input">
                    </div>
                    <div class="setting-item">
                        <label for="batchSizeInput">Batch Size:</label>
                        <input type="number" id="batchSizeInput" value="20" min="1" max="50" class="setting-input">
                    </div>
                </div>
            </div>
        </div>

        <!-- Right Panel - MuseTalk Stream -->
        <div class="stream-panel">
            <h1>Avatar Stream</h1>
            
                         <div class="video-container" id="videoContainer">
                 <div class="video-placeholder" id="videoPlaceholder">
                     Waiting for stream...
                 </div>
                 <canvas class="stream-video" id="streamVideo" alt="Avatar Stream"></canvas>
             </div>
            
            <div class="stream-status waiting" id="streamStatus">
                Ready to receive frames
            </div>
            
            <div class="stream-controls">
                <button class="record-button" id="playButton" disabled>
                    ‚ñ∂Ô∏è Play
                </button>
                <button class="record-button" id="pauseButton" disabled>
                    ‚è∏Ô∏è Pause
                </button>
            </div>
            
            <div class="stream-info" id="streamInfo">
                <p>Frames in buffer: <span id="frameCount">0</span></p>
                <p>Current frame: <span id="currentFrame">-</span></p>
                <p>Playback FPS: <span id="playbackFPS">-</span></p>
            </div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/4.7.2/socket.io.js"></script>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let startTime;
        let timerInterval;
        let socket; // WebSocket connection

        // Initialize WebSocket connection
        function initializeWebSocket() {
            socket = io();
            
            socket.on('connect', function() {
                console.log('Connected to WebSocket for real-time streaming');
                updateStreamStatus('waiting', 'WebSocket connected - ready for frames');
            });
            
            socket.on('disconnect', function() {
                console.log('Disconnected from WebSocket');
                updateStreamStatus('error', 'WebSocket disconnected - falling back to polling');
                // Fall back to polling if WebSocket disconnects
                startBufferPolling();
            });
            
            socket.on('connect_error', function(error) {
                console.log('WebSocket connection error:', error);
                updateStreamStatus('error', 'WebSocket connection failed - using polling');
                // Fall back to polling on connection error
                startBufferPolling();
            });
            
            socket.on('frame_update', function(data) {
                handleWebSocketFrameUpdate(data);
            });
            
            socket.on('status', function(data) {
                console.log('WebSocket status:', data.message);
            });
        }
        
        // Handle WebSocket frame updates
        function handleWebSocketFrameUpdate(data) {
            console.log('WebSocket frame update received:', data);
            
            // Track start signal
            if (data.start_signal_received && !start_signal_received_client) {
                start_signal_received_client = true;
                updateStreamStatus('streaming', 'Start signal received - ETA <= audio duration. Beginning playback...');
                console.log('WebSocket: Start signal received - ETA <= audio duration');
                
                // Start playback immediately when start signal is received
                if (frameBuffer.length > 0 && !isPlaying) {
                    console.log('WebSocket: Start signal received and frames available, starting playback');
                    currentFrameIndex = 0;
                    startPlayback();
                    
                    // Also start playing the audio file
                    if (audioPlayer.src) {
                        console.log('Starting audio playback');
                        audioPlayer.currentTime = 0; // Reset to beginning
                        audioPlayer.play().catch(error => {
                            console.log('Audio autoplay failed (browser policy):', error);
                        });
                    }
                }
            }

            // Check if we have new frames (frames are sent after each batch)
            if (data.frames && data.frames.length > 0) {
                // Only add frames that aren't already in the buffer
                const newFrames = data.frames.filter(newFrame => {
                    return !frameBuffer.some(existingFrame => 
                        existingFrame.frame_number === newFrame.frame_number
                    );
                });
                
                if (newFrames.length > 0) {
                    // Add only the new frames to the buffer
                    frameBuffer = frameBuffer.concat(newFrames);
                    console.log(`WebSocket buffer update: ${frameBuffer.length} frames (${newFrames.length} new from batch ${data.batch_number || 'unknown'})`);
                    
                    // Start playback if start signal has been received and we're not already playing
                    if (start_signal_received_client && !isPlaying) {
                        console.log('WebSocket: Start signal received and new frames available, starting playback');
                        if (currentFrameIndex === 0) {
                            currentFrameIndex = 0;
                        }
                        startPlayback();
                        
                        // Also start playing the audio file if not already playing
                        if (audioPlayer.src && audioPlayer.paused) {
                            console.log('Starting audio playback with new frames');
                            audioPlayer.currentTime = 0; // Reset to beginning
                            audioPlayer.play().catch(error => {
                                console.log('Audio autoplay failed (browser policy):', error);
                            });
                        }
                    }
                    
                    // Enable play button if we have frames and not already playing
                    if (frameBuffer.length > 0 && !isPlaying) {
                        playButton.disabled = false;
                    }
                }
            }
            
            // Check if processing is complete
            if (data.processing_complete || data.status === 'finished') {
                console.log('WebSocket: Processing complete');
                processing_complete = true;
                updateStreamStatus('streaming', 'Processing complete - all frames received');
                
                // If we're still playing and have reached the end, stop playback
                if (isPlaying && currentFrameIndex >= frameBuffer.length) {
                    console.log('Playback completed, stopping playback');
                    stopPlayback();
                    updateStreamStatus('waiting', 'Playback completed - all frames played');
                }
            }
        }

                 const recordButton = document.getElementById('recordButton');
        const status = document.getElementById('status');
        const audioPlayer = document.getElementById('audioPlayer');
        const timer = document.getElementById('timer');
        
        // Stream elements
        const videoContainer = document.getElementById('videoContainer');
        const videoPlaceholder = document.getElementById('videoPlaceholder');
        const streamVideo = document.getElementById('streamVideo');
        const streamStatus = document.getElementById('streamStatus');
        const frameCount = document.getElementById('frameCount');
        const currentFrame = document.getElementById('currentFrame');
        const playbackFPS = document.getElementById('playbackFPS');
        const playButton = document.getElementById('playButton');
        const pauseButton = document.getElementById('pauseButton');

                 recordButton.addEventListener('click', toggleRecording);
        playButton.addEventListener('click', startPlayback);
        pauseButton.addEventListener('click', stopPlayback);

        let isRecording = false;

        async function toggleRecording() {
            if (!isRecording) {
                // Start recording
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    mediaRecorder = new MediaRecorder(stream, {
                        mimeType: 'audio/webm;codecs=opus'
                    });

                    audioChunks = [];
                    mediaRecorder.ondataavailable = (event) => {
                        audioChunks.push(event.data);
                    };

                                         mediaRecorder.onstop = () => {
                         audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                         const audioUrl = URL.createObjectURL(audioBlob);
                         audioPlayer.src = audioUrl;
                         audioPlayer.classList.remove('hidden');
                         
                         // Automatically save and process the recording
                         saveAndProcessRecording();
                     };

                    mediaRecorder.start();
                    startTime = Date.now();
                    startTimer();
                    
                    isRecording = true;
                    recordButton.textContent = '‚èπÔ∏è Stop Recording';
                    recordButton.classList.add('recording');
                    
                    showStatus('Recording...', 'recording');
                    
                } catch (error) {
                    showStatus('Error accessing microphone: ' + error.message, 'error');
                }
            } else {
                // Stop recording
                if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                    mediaRecorder.stop();
                    mediaRecorder.stream.getTracks().forEach(track => track.stop());
                    
                    stopTimer();
                    isRecording = false;
                    recordButton.textContent = 'üéôÔ∏è Start Recording';
                    recordButton.classList.remove('recording');
                    
                    showStatus('Recording stopped. You can now save or record again.', 'success');
                }
            }
        }

                 async function saveAndProcessRecording() {
             if (!audioBlob) {
                 showStatus('No recording to save', 'error');
                 return;
             }
 
             try {
                 showStatus('Processing recording...', 'recording');
                 
                 // Convert to WAV format using Web Audio API
                 const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                 const arrayBuffer = await audioBlob.arrayBuffer();
                 const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                 
                 // Create WAV file
                 const wavBlob = audioBufferToWav(audioBuffer);
                 const wavUrl = URL.createObjectURL(wavBlob);
                 
                 // Convert to base64
                 const reader = new FileReader();
                 reader.onload = async function() {
                     const base64Data = reader.result;
                     
                     // Get settings values
                     const fps = document.getElementById('fpsInput').value;
                     const batchSize = document.getElementById('batchSizeInput').value;
                     
                     const response = await fetch('/save_audio', {
                         method: 'POST',
                         headers: {
                             'Content-Type': 'application/json',
                         },
                         body: JSON.stringify({
                             audio_data: base64Data,
                             fps: fps,
                             batch_size: batchSize
                         })
                     });
 
                     const result = await response.json();
                     
                     if (result.success) {
                         showStatus('Recording saved and sent to MuseTalk for processing', 'success');
                         
                         // Clear current buffer and stop playback
                         clearFrameBuffer();
                         currentFrameIndex = 0;
                         stopPlayback();
                         
                         // Reset button states
                         playButton.disabled = true;
                         pauseButton.disabled = true;
                         
                         updateStreamStatus('waiting', 'Waiting for frames via WebSocket...');
                         
                         // Request frames via WebSocket instead of polling
                         if (socket && socket.connected) {
                             console.log('Requesting frames via WebSocket');
                             socket.emit('request_frames');
                         } else {
                             console.log('WebSocket not connected, falling back to polling');
                             startBufferPolling();
                         }
                     } else {
                         showStatus('Error processing recording: ' + result.error, 'error');
                         updateStreamStatus('error', 'Processing failed');
                     }
                 };
                 reader.readAsDataURL(wavBlob);
                 
             } catch (error) {
                 showStatus('Error processing recording: ' + error.message, 'error');
                 updateStreamStatus('error', 'Connection error');
             }
         }

        function startTimer() {
            timerInterval = setInterval(() => {
                const elapsed = Date.now() - startTime;
                const minutes = Math.floor(elapsed / 60000);
                const seconds = Math.floor((elapsed % 60000) / 1000);
                timer.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
            }, 1000);
        }

        function stopTimer() {
            clearInterval(timerInterval);
            timer.textContent = '00:00';
        }

        function showStatus(message, type) {
            status.textContent = message;
            status.className = `status ${type}`;
            status.classList.remove('hidden');
            
            setTimeout(() => {
                status.classList.add('hidden');
            }, 5000);
        }

        

                                  function clearFrameBuffer() {
            // Stop any ongoing playback
            stopPlayback();
            
            // Clear the frame buffer
            frameBuffer = [];
            
            // Reset playback position
            currentFrameIndex = 0;
            
            // Reset processing completion status
            processing_complete = false;
            start_signal_received_client = false;
           
            // Clear the canvas display
            const canvas = streamVideo;
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            canvas.classList.remove('active');
            
            // Reset frame information
            frameCount.textContent = '0';
            currentFrame.textContent = '-';
            playbackFPS.textContent = '-';
            
            // Update status
            updateStreamStatus('waiting', 'Buffer cleared - ready for WebSocket frames');
            
            // Also clear the backend buffer
            fetch('/clear_buffer', { method: 'POST' })
                .then(response => response.json())
                .then(data => console.log('Backend buffer cleared:', data))
                .catch(error => console.error('Error clearing backend buffer:', error));
        }

        // Function to manually request frames via WebSocket
        function requestFramesViaWebSocket() {
            if (socket && socket.connected) {
                console.log('Manually requesting frames via WebSocket');
                socket.emit('request_frames');
                updateStreamStatus('waiting', 'Requesting frames via WebSocket...');
            } else {
                console.log('WebSocket not available, using polling');
                startBufferPolling();
            }
        }

        function updateStreamStatus(type, message) {
            streamStatus.textContent = message;
            streamStatus.className = `stream-status ${type}`;
            
            if (type === 'streaming') {
                videoContainer.classList.add('streaming');
                videoPlaceholder.style.display = 'none';
            } else {
                videoContainer.classList.remove('streaming');
                videoPlaceholder.style.display = 'block';
            }
        }

                 // Frame buffer and playback variables
         let frameBuffer = [];
         let currentFrameIndex = 0;
         let playbackInterval = null;
         let isPlaying = false;
         let targetFPS = 25;
         let processing_complete = false;
         let start_signal_received_client = false;
         
                 // Initialize canvas on page load
        function initializeCanvas() {
            const canvas = streamVideo;
            const ctx = canvas.getContext('2d');
            const container = videoContainer;
            
            // Set canvas size to match container
            canvas.width = container.clientWidth;
            canvas.height = container.clientHeight;
            
            console.log('Canvas initialized:', canvas.width, 'x', canvas.height);
            
            // Clear canvas with black background
            ctx.fillStyle = '#000000';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            // Show canvas
            canvas.classList.add('active');
        }
        
        // Initialize canvas when page loads
        window.addEventListener('load', function() {
            initializeCanvas();
            initializeWebSocket(); // Initialize WebSocket connection
        });
        
        // Also initialize on DOMContentLoaded for better reliability
        document.addEventListener('DOMContentLoaded', function() {
            initializeCanvas();
            initializeWebSocket(); // Initialize WebSocket connection
        });
        
        // Test function to verify canvas is working
        function testCanvas() {
            const canvas = streamVideo;
            const ctx = canvas.getContext('2d');
            
            // Draw a simple test pattern
            ctx.fillStyle = '#ff0000';
            ctx.fillRect(0, 0, canvas.width, canvas.height);
            
            ctx.fillStyle = '#00ff00';
            ctx.fillRect(50, 50, 100, 100);
            
            ctx.fillStyle = '#ffffff';
            ctx.font = '20px Arial';
            ctx.fillText('Canvas Test', 100, 150);
            
            console.log('Canvas test completed');
        }
        
        // Test canvas after initialization
        setTimeout(testCanvas, 1000);
        
        // Debug function to manually test frame display
        function debugFrameDisplay() {
            console.log('=== DEBUG FRAME DISPLAY ===');
            console.log('Frame buffer length:', frameBuffer.length);
            console.log('Canvas element:', streamVideo);
            console.log('Canvas dimensions:', streamVideo.width, 'x', streamVideo.height);
            console.log('Canvas context:', streamVideo.getContext('2d'));
            
            if (frameBuffer.length > 0) {
                console.log('First frame in buffer:', frameBuffer[0]);
                console.log('Frame data length:', frameBuffer[0].frame_data.length);
                
                // Try to display the first frame manually
                const firstFrame = frameBuffer[0];
                displayFrameImmediately(firstFrame);
            } else {
                console.log('No frames in buffer');
            }
            console.log('=== END DEBUG ===');
        }
        
        // Add debug button to test frame display
        const debugButton = document.createElement('button');
        debugButton.textContent = 'üêõ Debug Frames';
        debugButton.style.position = 'fixed';
        debugButton.style.top = '10px';
        debugButton.style.right = '10px';
        debugButton.style.zIndex = '1000';
        debugButton.onclick = debugFrameDisplay;
        document.body.appendChild(debugButton);
        
        // Add test frame button
        const testFrameButton = document.createElement('button');
        testFrameButton.textContent = 'üß™ Test Frame';
        testFrameButton.style.position = 'fixed';
        testFrameButton.style.top = '50px';
        testFrameButton.style.right = '10px';
        testFrameButton.style.zIndex = '1000';
        testFrameButton.onclick = function() {
            console.log('Creating test frame...');
            
            // Create a simple test image (red square)
            const canvas = document.createElement('canvas');
            canvas.width = 256;
            canvas.height = 256;
            const ctx = canvas.getContext('2d');
            
            // Draw a red square
            ctx.fillStyle = '#ff0000';
            ctx.fillRect(0, 0, 256, 256);
            
            // Add some text
            ctx.fillStyle = '#ffffff';
            ctx.font = '20px Arial';
            ctx.fillText('Test Frame', 50, 128);
            
            // Convert to blob
            canvas.toBlob(function(blob) {
                // Convert blob to base64
                const reader = new FileReader();
                reader.onload = function() {
                    const base64Data = reader.result.split(',')[1]; // Remove data URL prefix
                    
                    // Create fake frame object
                    const testFrame = {
                        frame_number: 999,
                        frame_data: base64Data,
                        timestamp: new Date().toISOString()
                    };
                    
                    console.log('Test frame created:', testFrame);
                    
                    // Add to buffer and display
                    frameBuffer.push(testFrame);
                    displayFrameImmediately(testFrame);
                };
                reader.readAsDataURL(blob);
            }, 'image/jpeg');
        };
        document.body.appendChild(testFrameButton);

        // Add WebSocket request button
        const wsRequestButton = document.createElement('button');
        wsRequestButton.textContent = 'üîå WS Request';
        wsRequestButton.style.position = 'fixed';
        wsRequestButton.style.top = '90px';
        wsRequestButton.style.right = '10px';
        wsRequestButton.style.zIndex = '1000';
        wsRequestButton.onclick = requestFramesViaWebSocket;
        document.body.appendChild(wsRequestButton);

                 function displayFrame(frameData, frameNumber) {
            // Create an image element to load the frame data
            const img = new Image();
            img.onload = function() {
                // Get canvas context
                const canvas = streamVideo;
                const ctx = canvas.getContext('2d');
                
                // Calculate scaling to fill entire canvas (cover mode)
                const scale = Math.max(
                    canvas.width / img.width,
                    canvas.height / img.height
                );
                
                const scaledWidth = img.width * scale;
                const scaledHeight = img.height * scale;
                
                // Center the image on canvas (may crop edges)
                const x = (canvas.width - scaledWidth) / 2;
                const y = (canvas.height - scaledHeight) / 2;
                
                // Clear canvas and draw the frame
                ctx.fillStyle = '#000000';
                ctx.fillRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(img, x, y, scaledWidth, scaledHeight);
                
                // Show canvas
                canvas.classList.add('active');
                
                // Update frame information (less frequent updates for performance)
                if (frameNumber % 5 === 0) {  // Update every 5 frames
                    frameCount.textContent = frameBuffer.length;
                    currentFrame.textContent = frameNumber;
                    playbackFPS.textContent = targetFPS;
                }
                
                // Update status less frequently for performance
                if (frameNumber % 10 === 0) {
                    updateStreamStatus('streaming', `Playing frame ${frameNumber} of ${frameBuffer.length}`);
                }
            };
            
            img.onerror = function() {
                console.error('Error loading image for frame:', frameNumber);
            };
            
            // Load the frame data
            img.src = URL.createObjectURL(new Blob([frameData], { type: 'image/jpeg' }));
        }

                 function startPlayback() {
             if (frameBuffer.length === 0) return;
             
             // If already playing, don't restart
             if (isPlaying) return;
             
             isPlaying = true;
             // Don't reset currentFrameIndex - continue from where we left off
             targetFPS = parseInt(document.getElementById('fpsInput').value) || 25;
            
            const frameInterval = 1000 / targetFPS; // milliseconds between frames
            
            playbackInterval = setInterval(() => {
                if (currentFrameIndex < frameBuffer.length) {
                    const frame = frameBuffer[currentFrameIndex];
                    const frameData = atob(frame.frame_data); // Decode base64
                    
                    // Convert string to Uint8Array for proper blob creation
                    const uint8Array = new Uint8Array(frameData.length);
                    for (let i = 0; i < frameData.length; i++) {
                        uint8Array[i] = frameData.charCodeAt(i);
                    }
                    
                    displayFrame(uint8Array, frame.frame_number);
                    currentFrameIndex++;
                                 } else {
                     // Reached end of current buffer
                     // Check if processing is complete - if so, stop playback
                     if (processing_complete) {
                         console.log('Reached end of buffer and processing is complete, stopping playback');
                         stopPlayback();
                         updateStreamStatus('waiting', 'Playback completed - all frames played');
                     } else {
                         // Wait for more frames to arrive
                         updateStreamStatus('streaming', `Waiting for more frames... (played ${currentFrameIndex} frames)`);
                     }
                 }
            }, frameInterval);
            
            // Update button states
            playButton.disabled = true;
            pauseButton.disabled = false;
            
                         updateStreamStatus('streaming', `Playing at ${targetFPS} FPS`);
             
             // Also start playing the audio file if available
             if (audioPlayer.src) {
                 console.log('Starting audio playback with video');
                 audioPlayer.currentTime = 0; // Reset to beginning
                 audioPlayer.play().catch(error => {
                     console.log('Audio autoplay failed (browser policy):', error);
                 });
             }
        }

        function stopPlayback() {
            isPlaying = false;
            if (playbackInterval) {
                clearInterval(playbackInterval);
                playbackInterval = null;
            }
            
            // Update button states
            playButton.disabled = false;
            pauseButton.disabled = true;
            
                         updateStreamStatus('waiting', 'Playback stopped');
             
             // Also pause the audio file
             if (audioPlayer.src) {
                 console.log('Pausing audio playback');
                 audioPlayer.pause();
             }
        }

                 // Note: Removed fetchFrameBuffer function since we no longer poll for frames
                 // Frames are now received directly via POST from MuseTalk service

                         function displayFrameImmediately(frame) {
            try {
                console.log('=== DISPLAY FRAME IMMEDIATELY ===');
                console.log('Frame object:', frame);
                console.log('Frame number:', frame.frame_number);
                console.log('Frame data type:', typeof frame.frame_data);
                console.log('Frame data length:', frame.frame_data.length);
                
                // Create blob from base64 data
                const frameData = atob(frame.frame_data); // Decode base64
                console.log('Decoded frame data length:', frameData.length);
                console.log('First 100 bytes:', frameData.substring(0, 100));
                
                // Convert string to Uint8Array for proper blob creation
                const uint8Array = new Uint8Array(frameData.length);
                for (let i = 0; i < frameData.length; i++) {
                    uint8Array[i] = frameData.charCodeAt(i);
                }
                
                // Create an image element to load the frame data
                const img = new Image();
                
                img.onload = function() {
                    console.log('‚úÖ Image loaded successfully!');
                    console.log('Image dimensions:', img.width, 'x', img.height);
                    
                    // Get canvas context
                    const canvas = streamVideo;
                    const ctx = canvas.getContext('2d');
                    
                    // Don't resize canvas every time, just use current dimensions
                    console.log('Canvas dimensions (immediate):', canvas.width, 'x', canvas.height);
                    
                                         // Calculate scaling to fill entire canvas (cover mode)
                     const scale = Math.max(
                         canvas.width / img.width,
                         canvas.height / img.height
                     );
                     
                     const scaledWidth = img.width * scale;
                     const scaledHeight = img.height * scale;
                     
                     console.log('Scaled dimensions (immediate):', scaledWidth, 'x', scaledHeight);
                     
                     // Center the image on canvas (may crop edges)
                     const x = (canvas.width - scaledWidth) / 2;
                     const y = (canvas.height - scaledHeight) / 2;
                    
                    console.log('Drawing position:', x, y);
                    
                    // Clear canvas and draw the frame
                    ctx.fillStyle = '#000000';
                    ctx.fillRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(img, x, y, scaledWidth, scaledHeight);
                    
                    // Show canvas
                    canvas.classList.add('active');
                    
                    // Update frame information
                    frameCount.textContent = frameBuffer.length;
                    currentFrame.textContent = frame.frame_number;
                    playbackFPS.textContent = targetFPS;
                    
                    // Update status
                    updateStreamStatus('streaming', `Received frame ${frame.frame_number} of ${frameBuffer.length}`);
                    
                    console.log('‚úÖ Frame displayed immediately successfully');
                    console.log('=== END DISPLAY FRAME ===');
                };
                
                img.onerror = function(error) {
                    console.error('‚ùå Error loading image immediately:', error);
                    console.error('Image src:', img.src);
                    console.error('Blob size:', blob.size);
                    console.error('Frame data length:', frame.frame_data.length);
                };
                
                // Load the frame data
                const blob = new Blob([uint8Array], { type: 'image/jpeg' });
                const url = URL.createObjectURL(blob);
                console.log('Created blob URL:', url);
                img.src = url;
                
            } catch (error) {
                console.error('‚ùå Error displaying frame immediately:', error);
                console.error('Error stack:', error.stack);
            }
        }

        // Simple polling to check for new frames (much less frequent than before)
        let bufferPollingInterval = null;

        function startBufferPolling() {
            if (bufferPollingInterval) {
                clearInterval(bufferPollingInterval);
            }
            bufferPollingInterval = setInterval(checkForNewFrames, 50); // Check every 50ms for maximum responsiveness
            console.log('Started high-frequency buffer checking for immediate streaming');
        }

        function stopBufferPolling() {
            if (bufferPollingInterval) {
                clearInterval(bufferPollingInterval);
                bufferPollingInterval = null;
                console.log('Stopped buffer checking');
            }
        }

        async function checkForNewFrames() {
            try {
                const response = await fetch('/get_frame_buffer?v=' + Date.now());
                if (response.ok) {
                    const result = await response.json();
                    
                    // Track start signal
                    if (result.start_signal_received && !start_signal_received_client) {
                        start_signal_received_client = true;
                        updateStreamStatus('streaming', 'Start signal received - ETA <= audio duration. Beginning playback...');
                        // Increase polling frequency even more after start signal
                        if (bufferPollingInterval) {
                            clearInterval(bufferPollingInterval);
                        }
                        bufferPollingInterval = setInterval(checkForNewFrames, 25); // Check every 25ms for maximum responsiveness
                    }

                    // Check if we have new frames (frames are sent after each batch)
                    if (result.frames && result.frames.length > frameBuffer.length) {
                        // Only add frames that aren't already in the buffer
                        const newFrames = result.frames.filter(newFrame => {
                            return !frameBuffer.some(existingFrame => 
                                existingFrame.frame_number === newFrame.frame_number
                            );
                        });
                        
                        if (newFrames.length > 0) {
                            // Add only the new frames to the buffer
                            frameBuffer = frameBuffer.concat(newFrames);
                            console.log(`Buffer updated: ${frameBuffer.length} frames (${newFrames.length} new)`);
                            
                            // Start playback if start signal has been received and we're not already playing
                            if (start_signal_received_client && !isPlaying) {
                                console.log('Start signal received and frames available, starting playback');
                                if (currentFrameIndex === 0) {
                                    currentFrameIndex = 0;
                                }
                                startPlayback();
                                
                                // Also start playing the audio file if not already playing
                                if (audioPlayer.src && audioPlayer.paused) {
                                    console.log('Starting audio playback');
                                    audioPlayer.currentTime = 0; // Reset to beginning
                                    audioPlayer.play().catch(error => {
                                        console.log('Audio autoplay failed (browser policy):', error);
                                    });
                                }
                            }
                            
                            // Enable play button if we have frames and not already playing
                            if (frameBuffer.length > 0 && !isPlaying) {
                                playButton.disabled = false;
                            }
                        }
                    }
                    
                    // Check if processing is complete
                    if (result.processing_complete) {
                        console.log('Processing complete, stopping buffer checking');
                        processing_complete = true;
                        stopBufferPolling();
                        updateStreamStatus('streaming', 'Processing complete - all frames received');
                        
                        // If we're still playing and have reached the end, stop playback
                        if (isPlaying && currentFrameIndex >= frameBuffer.length) {
                            console.log('Playback completed, stopping playback');
                            stopPlayback();
                            updateStreamStatus('waiting', 'Playback completed - all frames played');
                        }
                    }
                }
            } catch (error) {
                console.log('Error checking for new frames:', error);
            }
        }



        // Convert AudioBuffer to WAV format
        function audioBufferToWav(buffer) {
            const length = buffer.length;
            const numberOfChannels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            const arrayBuffer = new ArrayBuffer(44 + length * numberOfChannels * 2);
            const view = new DataView(arrayBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * numberOfChannels * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, numberOfChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * numberOfChannels * 2, true);
            view.setUint16(32, numberOfChannels * 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * numberOfChannels * 2, true);
            
            // Convert float samples to 16-bit PCM
            let offset = 44;
            for (let i = 0; i < length; i++) {
                for (let channel = 0; channel < numberOfChannels; channel++) {
                    const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
                    view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
                    offset += 2;
                }
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }
    </script>
</body>
</html>
